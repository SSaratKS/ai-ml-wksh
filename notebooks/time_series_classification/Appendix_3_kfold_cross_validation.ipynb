{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series classification - k-fold cross validation\n",
    "<a href=\"https://colab.research.google.com/github/jarusgnuj/ioctm358/blob/master/notebooks/time_series_classification/3_TSC_kfold_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "# General settings and variables\n",
    "sns.set_style('whitegrid')\n",
    "model_palette = ['rebeccapurple', 'mediumspringgreen']\n",
    "\n",
    "class_names = ['cement', 'carpet']\n",
    "class_colors = ['darkorange', 'steelblue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Functions\n",
    "Some functions, for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    ''' Load the data from a file in a GitHub repo '''\n",
    "    url_root = 'https://raw.githubusercontent.com/jarusgnuj/ai-ml-wksh/master/data/UCR_TSC_archive/SonyAIBORobotSurface1_IoC'\n",
    "    url = url_root+'/'+filename\n",
    "    robot_df = pd.read_csv(url, sep='\\t', header=None)\n",
    "    print('Loaded from', url)\n",
    "    robot_data = robot_df.values\n",
    "    print('The shape of robot_data is', robot_data.shape)\n",
    "    return robot_data\n",
    "\n",
    "\n",
    "def preprocess_data(robot_data):\n",
    "    ''' Split the data in to data samples and labels. Convert classlabels in to 0 and 1 '''\n",
    "    labels = robot_data[:,0]\n",
    "    data_samples = robot_data[:,1:]\n",
    "    print('The shape of the data matrix is', data_samples.shape)\n",
    "    print('The shape of the labels vector is', labels.shape)\n",
    "\n",
    "    # Change from classes 1 and 2 to classes 0 and 1, for convenience of use with Keras\n",
    "    labels = labels - 1\n",
    "    labels = labels.astype(int)\n",
    "    print('Number of samples of class 0', (labels == 0).sum())\n",
    "    print('Number of samples of class 1', (labels == 1).sum())\n",
    "\n",
    "    return data_samples, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Load the development dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SonyAIBORobotSurface1_IoC_DEV.txt'\n",
    "robot_data = load_data(filename)\n",
    "data, labels = preprocess_data(robot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 MLP\n",
    "Create a function that builds our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of the input vector\n",
    "input_dim = data.shape[1]\n",
    "print('input_dim:', input_dim)\n",
    "\n",
    "def build_model():\n",
    "    ''' Return a model with randomly initialised weights '''\n",
    "    ### CHANGE PARAMETERS HERE ###\n",
    "    # Change the number of nodes in each layer.\n",
    "    # Add or remove layers.\n",
    "    model = Sequential([\n",
    "        Dense(16, input_dim=input_dim, activation='relu', name='Layer1'), \n",
    "        Dense(8, activation='relu', name='Layer2'), \n",
    "        Dense(1, activation='sigmoid', name='OutputLayer')\n",
    "    ])\n",
    "    ### END OF CHANGE PARAMETERS ###\n",
    "    optimizer = keras.optimizers.Adam() \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Repeated k-fold cross validation\n",
    "k-fold cross validation splits the dataset into k equal sets. Training is performed on k-1 of the sets and testing is performed on the remaining set. This is repeated m times.\n",
    "\n",
    "![Example of splitting the dataset into 5 subsets; 5 folds. Training uses 4 of the folds and testing (validation) is done on the fifth fold. This is then repeated 5 times, using a different fold for testing each time](images/5fold_cross_validation.png \"Data splitting for 5-fold cross validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 444\n",
    "k = 3 ### CHANGE PARAMETER HERE ###\n",
    "subset_size = dataset_size / k\n",
    "training_set_size = round((k-1)*subset_size)\n",
    "test_set_size = dataset_size - training_set_size\n",
    "print('With k =', k, 'we would train using', training_set_size, 'data samples and test using', test_set_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Exercise 3a: Set k and m\n",
    "+ How many data samples do you want to use for training and for testing?\n",
    "  + Set k accordingly.\n",
    "+ How many times do you want to repeat the model training and testing?\n",
    "  + Set m accordingly.\n",
    "\n",
    "\n",
    "Look at the box plot below. How variable are your results? When you train your final model, you'll train it once, are you confident that you'll get an accurate model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE PARAMETERS HERE ###\n",
    "k = 3 \n",
    "m = 5 \n",
    "batch_size = 10\n",
    "epochs = 30\n",
    "### END OF CHANGE PARAMETERS ###\n",
    "\n",
    "kfold = RepeatedStratifiedKFold(n_splits=k, n_repeats=m, random_state=76)\n",
    "count = 0\n",
    "val_acc = list()\n",
    "start = time.time()\n",
    "for train, test in kfold.split(data, labels):\n",
    "    data_train, labels_train, data_test, labels_test = data[train], labels[train], data[test], labels[test]\n",
    "    # Build and train a model\n",
    "    model = build_model()\n",
    "    fold_start = time.time()\n",
    "    hist = model.fit(data_train, labels_train, batch_size=batch_size, epochs=epochs, validation_data=(data_test, labels_test), verbose=1)\n",
    "    fold_end = time.time()\n",
    "    log = pd.DataFrame(hist.history) \n",
    "    print('Training of iteration', count, 'complete in', round(fold_end-fold_start), 'seconds')\n",
    "    val_acc.append(log.iloc[-1]['val_acc'])\n",
    "    count = count + 1\n",
    "\n",
    "end = time.time()\n",
    "val_acc = pd.DataFrame(val_acc, columns=['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_acc)\n",
    "print(m, 'repeats of', k, '-fold cross validation completed in', round(end-start), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Plot the k-fold cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=val_acc)\n",
    "ax = sns.swarmplot(data=val_acc, color='black')\n",
    "plt.title('k-fold cross validation results')\n",
    "ax.set_ylabel('Validation accuracy')\n",
    "print('Validation accuracy mean:', val_acc['val_acc'].mean())\n",
    "print('Sample standard deviation:', val_acc['val_acc'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of exercise 3a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Exercise 3b: Model development\n",
    "In the build_model function you can change the number of nodes in each layer. You can also add and remove layers to change the number of layers. These are some of the model's \"hyperparameters\". Change model hyperparameters and evaluate the model using the k-fold cross validation.\n",
    "+ What hyperparameter settings give the highest mean validation accuracy with the lowest variability?\n",
    "+ What hyperparameters do you want to use to train and model and then test it on the final test dataset?\n",
    "\n",
    "\n",
    "Use the dropout layer described below if you wish.\n",
    "\n",
    "## Competition part I\n",
    "+ The best development model - highest mean validation accuracy. \n",
    "+ Tie-breaker - the lowest sample standard deviation.\n",
    "\n",
    "## Competition part II \n",
    "This is in the next notebook.\n",
    "+ Best performing model - the highest accuracy when tested on the final test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Optional: Dropout\n",
    "Dropout can improve a model's generalisation. It can prevent a model from overfitting to the training data. Overfitting can result in high training accuracy but low validation accuracy. \n",
    "+ Does your model suffer from this?\n",
    "+ What happens if you increase the number nodes in the model does validation accuracy start to decrease, suggesting that overfitting is occurring?\n",
    "\n",
    "Try adding dropout layers to your model. An example of such a model is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_dropout(print_summary=False):\n",
    "    ''' Return a model with randomly initialised weights. The model uses dropout. '''\n",
    "    ### CHANGE PARAMETERS HERE ###\n",
    "    # Change the number of nodes and layers.\n",
    "    # Change the proportion of nodes \"dropped out\", from 0 up to 1.\n",
    "    model = Sequential([\n",
    "        Dense(16, input_dim=input_dim, activation='relu', name='Layer1'), \n",
    "        Dropout(0.1,name='Dropout1'),\n",
    "        Dense(8, activation='relu', name='Layer2'), \n",
    "        Dropout(0.1,name='Dropout2'),\n",
    "        Dense(1, activation='sigmoid', name='OutputLayer')\n",
    "    ])\n",
    "    ### END OF CHANGE PARAMETERS ###\n",
    "    optimizer = keras.optimizers.Adam() \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    if print_summary:\n",
    "        print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "model_with_dropout = build_model_with_dropout(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
