{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model and test it on the final test dataset\n",
    "<a href=\"https://colab.research.google.com/github/jarusgnuj/ioctm358/blob/master/notebooks/time_series_classification/4_TSC_final_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Exercise 4a : Competition part II\n",
    "In notebook 3 you used the development dataset and performed a hyperparameter search. You selected a set of hyperparameters that you believe will generate the best performing model. Now we'll test it out on previously unseen data, the final test dataset.\n",
    "\n",
    "\n",
    "Copy in your build_model function where indicated in a cell below.\n",
    "\n",
    "\n",
    "+ Best performing model - the highest accuracy when tested on the final test dataset.\n",
    "+ Tie-breaker - the highest accuracy on the last sample in the final test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# General settings\n",
    "sns.set_style('whitegrid')\n",
    "model_palette = ['rebeccapurple', 'mediumspringgreen']\n",
    "\n",
    "class_names = ['cement', 'carpet']\n",
    "class_colors = ['darkorange', 'steelblue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Functions\n",
    "Some functions, for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    ''' Load the data from a file in a GitHub repo '''\n",
    "    url_root = 'https://raw.githubusercontent.com/jarusgnuj/ai-ml-wksh/master/data/UCR_TSC_archive/SonyAIBORobotSurface1_IoC'\n",
    "    url = url_root+'/'+filename\n",
    "    robot_df = pd.read_csv(url, sep='\\t', header=None)\n",
    "    print('Loaded from', url)\n",
    "    robot_data = robot_df.values\n",
    "    print('The shape of robot_data is', robot_data.shape)\n",
    "    return robot_data\n",
    "\n",
    "\n",
    "def preprocess_data(robot_data):\n",
    "    ''' Split the data in to data samples and labels. Convert classlabels in to 0 and 1 '''\n",
    "    labels = robot_data[:,0]\n",
    "    data_samples = robot_data[:,1:]\n",
    "    print('The shape of the data matrix is', data_samples.shape)\n",
    "    print('The shape of the labels vector is', labels.shape)\n",
    "\n",
    "    # Change from classes 1 and 2 to classes 0 and 1, for convenience of use with Keras\n",
    "    labels = labels - 1\n",
    "    labels = labels.astype(int)\n",
    "    print('Number of samples of class 0', (labels == 0).sum())\n",
    "    print('Number of samples of class 1', (labels == 1).sum())\n",
    "\n",
    "    return data_samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = load_data('SonyAIBORobotSurface1_IoC_DEV.txt')\n",
    "data_train, labels_train = preprocess_data(dev_data)\n",
    "\n",
    "final_test_data = load_data('SonyAIBORobotSurface1_IoC_FINAL_TEST.txt')\n",
    "data_final_test, labels_final_test = preprocess_data(final_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Paste in your build model function and other hyperparameters\n",
    "+ Copy in your selected model below.\n",
    "+ Set other hyperparameters - epochs and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = data_train.shape[1]\n",
    "\n",
    "def build_model(print_summary=False):\n",
    "    ''' Return a model with randomly initialised weights '''\n",
    "    ### Insert code here ###\n",
    "    # Copy in the code to build your selected model.\n",
    "    model = Sequential([\n",
    "        Dense(16, input_dim=input_dim, activation='relu', name='Layer1'),\n",
    "        Dense(8, activation='relu', name='Layer2'), \n",
    "        Dense(1, activation='sigmoid', name='OutputLayer')\n",
    "    ])\n",
    "    ### End of insert code ###\n",
    "    optimizer = keras.optimizers.Adam() \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    if print_summary:\n",
    "        print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "batch_size = 5 ### CHANGE PARAMETER HERE ###\n",
    "epochs = 50    ### CHANGE PARAMETER HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Train your model \n",
    "Train your model using all of the development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(data_train, labels_train, batch_size=batch_size, epochs=epochs, \n",
    "                 validation_data=(data_final_test, labels_final_test), verbose=1)\n",
    "end = time.time()\n",
    "log = pd.DataFrame(hist.history) \n",
    "print('Training complete in', str(round(end-start)), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(data_final_test, labels_final_test, batch_size=batch_size)\n",
    "print('Validation accuracy is', result[1])\n",
    "\n",
    "# Plot the log's accuracy data.\n",
    "ax = log[['acc', 'val_acc']].plot(title='Accuracy during training', color=model_palette)\n",
    "ax.set_xlabel(\"Model training epoch\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.legend([\"training\", \"final test\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Tie-breaker\n",
    "How does your model perform on the last sample in the final test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = -1 # In Python, -1 means the last element in the array\n",
    "data_sample = data_final_test[sample_num]\n",
    "data_sample = np.array( [data_sample,] )\n",
    "probability = model.predict(data_sample)\n",
    "print('Model: probability of belonging to class 1:', probability[0][0])\n",
    "print('Pred class:', (np.round(probability)[0][0].astype(int)))\n",
    "print('True class:', labels_final_test[sample_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of exercise 4a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Save and reload the model\n",
    "This trained model can now be saved and used again on another day, or on another machine. It doesn't need to be re-trained every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_save_and_load = False ### CHANGE PARAMETER HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a JSON file\n",
    "model_file = 'model.json'\n",
    "model_weights_file = 'model.h5'\n",
    "if do_save_and_load:\n",
    "    model_json = model.to_json()\n",
    "    with open(model_file, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # Save the model's weights to an HDF5 file\n",
    "    model.save_weights(model_weights_file)\n",
    "    print('Model saved to file', model_file)\n",
    "    print('Model weights saved to file', model_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_save_and_load:\n",
    "    json_file = open(model_file, 'r')\n",
    "    loaded_json_model = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_json_model)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(model_weights_file)\n",
    "    print('Model loaded from files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Compile and use the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_save_and_load:\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    loaded_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    result = loaded_model.evaluate(data_final_test, labels_final_test, batch_size=batch_size)\n",
    "    print('Loaded model: validation accuracy is', result[1])\n",
    "    labels_probability = loaded_model.predict_on_batch(data_final_test)\n",
    "    labels_predicted_class = np.round(labels_probability).flatten()\n",
    "    print('Some of the test results:')\n",
    "    print('True', labels_final_test[:23])\n",
    "    print('Pred', labels_predicted_class[:23].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
